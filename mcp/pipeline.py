from troposphere.stepfunctions import StateMachine

from troposphere.awslambda import Code, Function

from troposphere import (
    GetAtt,
    GetAZs,
    Join,
    Output,
    Parameter,
    Ref,
    Select,
    Tags,
    Template,
)

from troposphere.iam import (
    PolicyType,
    Role
)
from troposphere.ec2 import (
    SecurityGroup,
    SecurityGroupIngress
)
from troposphere.ec2 import (
    EIP,
    VPC,
    Instance,
    InternetGateway,
    NetworkAcl,
    NetworkAclEntry,
    NetworkInterfaceProperty,
    PlacementGroup,
    PortRange,
    Route,
    RouteTable,
    SecurityGroup,
    SecurityGroupIngress,
    SecurityGroupRule,
    Subnet,
    SubnetNetworkAclAssociation,
    SubnetRouteTableAssociation,
    VPCGatewayAttachment,
    VPCEndpoint,
)

from troposphere.batch import (
    ComputeEnvironment,
    ComputeEnvironmentOrder,
    ComputeResources,
    JobQueue,
    LaunchTemplateSpecification
)

from workflow import get_workflow

t = Template()
t.set_version("2010-09-09")
t.set_transform('AWS::Serverless-2016-10-31')

vpc = t.add_resource(
    VPC(
        "VPC",
        CidrBlock = "10.192.0.0/16",
        EnableDnsHostnames=True,
        EnableDnsSupport=True,
        Tags=Tags(Name="VPC - Data Science Pipeline", CreatedBy='data-science-pipeline'),
    )
)

publicsubnet1 = t.add_resource(
    Subnet(
        "PublicSubnet1",
        CidrBlock="10.192.10.0/24",
        VpcId=Ref(vpc),
        AvailabilityZone=Select(0, GetAZs('')),
        MapPublicIpOnLaunch=False,
        Tags=Tags(Name="PublicSubnet1 - Data Science Pipeline", CreatedBy='data-science-pipeline'),
    )
)

publicroutetable1=t.add_resource(
    RouteTable(
        "PublicRouteTable1",
        VpcId=Ref(vpc),
        Tags=Tags(Name="PublicRouteTable1 - Data Science Pipeline", CreatedBy='data-science-pipeline'),
    )
)

internetgateway=t.add_resource(
    InternetGateway(
        "InternetGateway",
        Tags=Tags(Name="InternetGateway - Data Science Pipeline", CreatedBy='data-science-pipeline'),
    )
)

gatewayAttachment = t.add_resource(
    VPCGatewayAttachment(
        "AttachGateway", VpcId=Ref(vpc), InternetGatewayId=Ref(internetgateway)
    )
)

routepublic1 = t.add_resource(
    Route(
        "RoutePublic1",
        DependsOn="AttachGateway",
        GatewayId=Ref("InternetGateway"),
        DestinationCidrBlock="0.0.0.0/0",
        RouteTableId=Ref(publicroutetable1),
    )
)

pubroutetableassociation1=t.add_resource(
    SubnetRouteTableAssociation(
        "PublicSubnet1RouteTableAssociation",
        RouteTableId=Ref(publicroutetable1),
        SubnetId=Ref(publicsubnet1)
    )
)

clustersecuritygroup=t.add_resource(
    SecurityGroup(
        "ClusterSecurityGroup",
        GroupDescription="Cluster default security group",
        VpcId=Ref(vpc),
        Tags=Tags(CreatedBy='data-science-pipeline'),
    )
)

clustersecuritygroupingress=t.add_resource(
    SecurityGroupIngress(
        "ClusterSecurityGroupIngress",
        GroupId=Ref(clustersecuritygroup),
        IpProtocol="tcp",
        FromPort=8000,
        ToPort=8200,
        SourceSecurityGroupId=Ref(clustersecuritygroup),
        DependsOn="ClusterSecurityGroup",
    )
)

instancerole=t.add_resource(
    Role(
        "InstanceRole",
        AssumeRolePolicyDocument={
            "Version": "2012-10-17",
            "Statement": [
                {
                    "Action": "sts:AssumeRole",
                    "Principal": {"Service": ["ec2.amazonaws.com"]},
                    "Effect": "Allow",
                }
            ],
        },
        Path="/"
    )
)

instancepolicy=t.add_resource(
    PolicyType(
        "InstancePolicy",
        PolicyName="DaskExecutionPolicy",
        PolicyDocument={
            "Version": "2012-10-17",
            "Statement": [
                {
                    "Action": [
                        "ec2:DescribeTags",
                        "ecs:CreateCluster",
                        "ecs:DeregisterContainerInstance",
                        "ecs:DiscoverPollEndpoint",
                        "ecs:Poll",
                        "ecs:RegisterContainerInstance",
                        "ecs:StartTelemetrySession",
                        "ecs:UpdateContainerInstancesState",
                        "ecs:Submit*",
                        "ecr:GetAuthorizationToken",
                        "ecr:BatchCheckLayerAvailability",
                        "ecr:GetDownloadUrlForLayer",
                        "ecr:BatchGetImage",
                    ],
                    "Resource": ["*"],
                    "Effect": "Allow",
                    "Sid": "AllowPull",
                },
                {
                    "Action": [
                        "logs:CreateLogGroup",
                        "logs:CreateLogStream",
                        "logs:PutLogEvents"
                    ],
                    "Resource": ["*"],
                    "Effect": "Allow",
                    "Sid": "AllowLogs",
                },
            ],
        },
        Roles=[Ref("InstanceRole")],
    )
)

placementgroup=t.add_resource(
    PlacementGroup(
        "ClusterPlacementGroup",
         Strategy="cluster"
    )
)

computeenvironment=t.add_resource(
    ComputeEnvironment(
        "DataScienceComputeEnvironment",
        ComputeEnvironmentName="data-science-compute-environment-cpu",
        ComputeResources=ComputeResources(
            MaxvCpus=128,
            MinvCpus=0,
            DesiredvCpus=0,
            InstanceTypes=[
                "c5",
                "c5a"
            ],
            Type="EC2",
            InstanceRole=Ref(instancerole),
            PlacementGroup=Ref(placementgroup),
            Subnets=[Ref(publicsubnet1)],
            SecurityGroupIds=[GetAtt(clustersecuritygroup, "GroupId")]
        ),
        State="ENABLED",
        Type="MANAGED",
    )
)

processingjobqueu=t.add_resource(
    JobQueue(
        "ProcessingJobQueue",
        JobQueueName="processing-job-queue",
        ComputeEnvironmentOrder=[
            ComputeEnvironmentOrder(
                ComputeEnvironment=Ref(computeenvironment),
                Order=0 
            )
        ],
        Priority=1,
        State="ENABLED"
    )
)

trainingjobqueu=t.add_resource(
    JobQueue(
        "TrainingJobQueue",
        JobQueueName="training-job-queue",
        ComputeEnvironmentOrder=[
            ComputeEnvironmentOrder(
                ComputeEnvironment=Ref(computeenvironment),
                Order=0 
            )
        ],
        Priority=2,
        State="ENABLED"
    )
)

optimizationjobqueu=t.add_resource(
    JobQueue(
        "OptimizationJobQueue",
        JobQueueName="optimization-job-queue",
        ComputeEnvironmentOrder=[
            ComputeEnvironmentOrder(
                ComputeEnvironment=Ref(computeenvironment),
                Order=0 
            )
        ],
        Priority=3,
        State="ENABLED"
    )
)

evaluationjobqueu=t.add_resource(
    JobQueue(
        "EvaluationJobQueue",
        JobQueueName="evaluation-job-queue",
        ComputeEnvironmentOrder=[
            ComputeEnvironmentOrder(
                ComputeEnvironment=Ref(computeenvironment),
                Order=0 
            )
        ],
        Priority=4,
        State="ENABLED"
    )
)

generator_code="""
def handler(event, context):
    print(event)
    return {
        "Iterator": ["I"] * min(500, max(event.get("Range", 1), 1))
    }
"""

lambdarole=t.add_resource(
    Role(
        "LambdaRole",
        Path="/",
        AssumeRolePolicyDocument={
            "Version": "2012-10-17",
            "Statement": [
                {
                    "Action": ["sts:AssumeRole"],
                    "Effect": "Allow",
                    "Principal": {"Service": ["lambda.amazonaws.com"]},
                }
            ],
        },
    )
)

lambdapolicy=t.add_resource(
    PolicyType(
        "LambdaPolicy",
        PolicyName="LambdaPolicy",
        PolicyDocument={
            "Version": "2012-10-17",
            "Statement": [
                {
                    "Action": ["logs:*"],
                    "Resource": "arn:aws:logs:*:*:*",
                    "Effect": "Allow",
                }
            ],
        },
        Roles=[Ref("LambdaRole")],
    )
)

generator=t.add_resource(
    Function(
        "Generator",
        Code=Code(ZipFile=generator_code),
        Handler="index.handler",
        Role=GetAtt(lambdarole, "Arn"),
        Runtime="python3.9",
        MemorySize=128,
        Timeout=3,
    )
)

pipelinerole=t.add_resource(
    Role(
        "PipelineRole",
        AssumeRolePolicyDocument={
            "Version": "2012-10-17",
            "Statement": [
                {
                    "Action": "sts:AssumeRole",
                    "Principal": {"Service": ["states.amazonaws.com"]},
                    "Effect": "Allow",
                },
            ],
        },
        Path="/"
    )
)

pipelinepolicy=t.add_resource(
    PolicyType(
        "PipelinePolicy",
        PolicyName="PipelinePolicy",
        PolicyDocument={
            "Version": "2012-10-17",
            "Statement": [
                {
                    "Action": [
                        "ecs:*",
                        "lambda:*",
                        "iam:PassRole"
                    ],
                    "Resource": ["*"],
                    "Effect": "Allow",
                    "Sid": "AllowRun",
                },
                {
                    "Action": [
                        "logs:CreateLogGroup",
                        "logs:CreateLogStream",
                        "logs:PutLogEvents"
                    ],
                    "Resource": ["*"],
                    "Effect": "Allow",
                    "Sid": "AllowLogs",
                },
            ],
        },
        Roles=[Ref("PipelineRole")],
    )
)

#pipeline=t.add_resource(StateMachine(
#    'Pipeline',
#    StateMachineName='data-science-pipeline',
#    StateMachineType='STANDARD',
#    RoleArn=GetAtt(pipelinerole, "Arn"),
#    DefinitionString=get_workflow(),
#    DefinitionSubstitutions={
#        "subnet1": Ref(publicsubnet1),
#        "securitygroup": Ref(clustersecuritygroup),
#        "generatorlambda": Ref(generator),
#    }
#))

with open('pipeline.yml', 'w') as f:
    f.write(t.to_yaml())


